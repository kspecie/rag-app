services:
#RAG Application 
  rag-app:
    build:
      context: .
      dockerfile: Dockerfile
    image: rag-app-image
    container_name: rag-app
    env_file:
      - ./.env
    ports:
      - "8000:8000"
    volumes:
      - .:/rag-app
      - /shared/models:/models
    environment:
      API_KEY: ${API_KEY}
      TEI_URL: ${TEI_SERVICE_URL}
      HF_TOKEN: "${HF_TOKEN}"
      CHROMA_HOST: "chromadb_service"
      CHROMA_PORT: "8000"
      LANGSMITH_TRACING: ${LANGSMITH_TRACING}
      LANGSMITH_API_KEY: ${LANGSMITH_API_KEY}

    depends_on:
      - tei_service
      - chromadb_service
      - tgi_service

 
    working_dir: /rag-app
    command: ["/bin/bash"]
    stdin_open: true
    tty: true


  # Text Embeddings Inference (TEI) Server
  tei_service:
    #image: ghcr.io/huggingface/text-embeddings-inference:hpu-latest # Use Hugging Face's TEI image
    image: ghcr.io/huggingface/text-embeddings-inference:cpu-ipex-latest
    container_name: tei_service
    #runtime: habana
    volumes:
      - /shared/models:/models # Mount shared models for TEI to access embedding models
    environment:
      MODEL_ID: BAAI/bge-small-en-v1.5 #embedding model for TEI to load OR could be in shared/models/hub
      #HABANA_VISIBLE_DEVICES: "1"
      OMPI_MCA_btl_vader_single_copy_mechanism: none
      MAX_WARMUP_SEQUENCE_LENGTH: "512"
      #DEVICE: hpu
    ports:
      - "8004:80"
    cap_add:
      - SYS_NICE
    ipc: host
    restart: "no"
    
#Text Generation Inference (TGI)
  tgi_service:
    #image: ghcr.io/huggingface/tgi-gaudi:2.3.1
    image: ghcr.io/huggingface/text-generation-inference:3.3.4-intel-cpu
    container_name: tgi_service
    #runtime: habana
    volumes: 
      - /shared/models:/models
    # volumes: 
    #     - /shared/models/hub/models--m42-health--Llama3-Med42-70B/snapshots/867064e18aad7bf3f4795f20dcb25a1108952543:/models

    environment:
      MODEL_ID: "m42-health/Llama3-Med42-8B" 
      HUGGINGFACE_HUB_CACHE: "/data" 
      #MODEL_ID: "${TGI_MODEL_PATH}"
      #MODEL_ID: "."
      NUM_SHARD: 2
      #HABANA_VISIBLE_DEVICES: "0"
      OMPI_MCA_btl_vader_single_copy_mechanism: "none"
      HF_TOKEN: "${HF_TOKEN}"
      MAX_INPUT_TOKENS: "5000"
      MAX_TOTAL_TOKENS: "8000"
    ports:
      - "8002:80"
    cap_add:
      - SYS_NICE
    ipc: host
    restart: "no"

  #ChromaDB Vector
  chromadb_service:
    image: chromadb/chroma:latest
    container_name: chromadb_service
    ports:
      - "8003:8000"
    environment:
      - IS_PERSISTENT=TRUE
      - PERSIST_DIRECTORY=/chroma/chroma
      - ANONYMIZED_TELEMETRY=FALSE
    volumes:
      - chroma_data:/chroma/chroma

volumes:
  chroma_data: