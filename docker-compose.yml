services:
#RAG Application 
  rag-app:
    build:
      context: .
      dockerfile: Dockerfile
    image: rag-app-image
    container_name: rag_app
    env_file:
      - ./.env
    ports:
      - "8000:8000"
    volumes:
      - .:/rag_app
      - /shared/models:/models
    environment:
      TEI_URL: ${TEI_API_URL}
      HF_TOKEN: "${HF_TOKEN}"
      CHROMA_HOST: "chromadb_service"
      CHROMA_PORT: "8000"
      LANGSMITH_TRACING: ${LANGSMITH_TRACING}
      LANGSMITH_API_KEY: ${LANGSMITH_API_KEY}

    depends_on:
      - tei_service
      - chromadb_service
      - tgi_service

 
    working_dir: /rag_app
    command: ["/bin/bash"]
    stdin_open: true
    tty: true


  # Text Embeddings Inference (TEI) Server
  tei_service:
    image: ghcr.io/huggingface/text-embeddings-inference:hpu-latest # Use Hugging Face's TEI image
    container_name: tei_service
    runtime: habana
    volumes:
      - /shared/models:/models # Mount shared models for TEI to access embedding models
    environment:
      MODEL_ID: BAAI/bge-small-en-v1.5 #embedding model for TEI to load OR could be in shared/models/hub
      HABANA_VISIBLE_DEVICES: "1"
      OMPI_MCA_btl_vader_single_copy_mechanism: none
      MAX_WARMUP_SEQUENCE_LENGTH: "512"
    ports:
      - "8001:80"
    cap_add:
      - SYS_NICE
    ipc: host
    restart: unless-stopped

#Text Generation Inference (TGI)
  tgi_service:
    image: ghcr.io/huggingface/tgi-gaudi:2.3.1
    container_name: tgi_service
    runtime: habana
    volumes: 
      - /shared/models:/models
    environment:
      MODEL_ID: "${TGI_MODEL_PATH}"
      NUM_SHARD: 1
      HABANA_VISIBLE_DEVICES: "0"
      OMPI_MCA_btl_vader_single_copy_mechanism: "none"
      HF_TOKEN: "${HF_TOKEN}"
      MAX_INPUT_TOKENS: "1024"
      MAX_TOTAL_TOKENS: "2048"
    ports:
      - "8002:80"
    cap_add:
      - SYS_NICE
    ipc: host
    restart: unless-stopped

  #ChromaDB Vector
  chromadb_service:
    image: chromadb/chroma:latest
    container_name: chromadb_service
    ports:
      - "8003:8000"
    environment:
      - IS_PERSISTENT=TRUE
      - PERSIST_DIRECTORY=/chroma/chroma
      - ANONYMIZED_TELEMETRY=FALSE
    volumes:
      - chroma_data:/chroma/chroma

volumes:
  chroma_data: