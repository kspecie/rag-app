services:
  rag-app:
    build:
      context: .
      dockerfile: Dockerfile
    image: rag-app-image
    container_name: rag_app
    env_file:
      - ./.env
    ports:
      - "8000:8000"
    volumes:
      - .:/rag_app
      - /shared/models:/models
    environment:
      TEI_URL: ${TEI_URL}
      HF_TOKEN: "${HF_TOKEN}"
      PG_CONNECTION_STRING: "${DATABASE_URL}"
    depends_on:
      tei_service:
        condition: service_healthy
      pgvector_db:
        condition: service_healthy
      tgi_service:
        condition: service_healthy
      retriever:
        condition: service_healthy
    working_dir: /rag_app
    command: ["/bin/bash"]
    stdin_open: true
    tty: true


  # Text Embeddings Inference (TEI) Server
  tei_service:
    image: ghcr.io/huggingface/text-embeddings-inference:hpu-latest # Use Hugging Face's TEI image
    container_name: tei_service
    runtime: habana
    volumes:
      - /shared/models:/models # Mount shared models for TEI to access embedding models
    environment:
      MODEL_ID: BAAI/bge-base-en-v1.5 #embedding model for TEI to load OR could be in /models/hub
      HABANA_VISIBLE_DEVICES: "1"
      OMPI_MCA_btl_vader_single_copy_mechanism: none
      MAX_WARMUP_SEQUENCE_LENGTH: "512"
    ports:
      - "9002:80"
    cap_add:
      - SYS_NICE
    ipc: host
    restart: unless-stopped

#Text Generation Inference (TGI)
  tgi_service:
    image: ghcr.io/huggingface/tgi-gaudi:2.3.1
    container_name: tgi_service
    runtime: habana
    volumes: 
      - /shared/models:/models
    environment:
      MODEL_ID: "${TGI_MODEL_PATH}"
      NUM_SHARD: 1
      HABANA_VISIBLE_DEVICES: "0"
      OMPI_MCA_btl_vader_single_copy_mechanism: "none"
      HF_TOKEN: "${HF_TOKEN}"
      MAX_INPUT_TOKENS: "1024"
      MAX_TOTAL_TOKENS: "2048"
    ports:
      - "8080:80"
    cap_add:
      - SYS_NICE
    ipc: host
    restart: unless-stopped

#PGVector Database Container
  pgvector_db:
    image: pgvector/pgvector:pg16
    container_name: kayla_postgres_vectordb
    environment:
      POSTGRES_PASSWORD: ${POSTGRES_PASSWORD}
      POSTGRES_USER: ${POSTGRES_USER}
      POSTGRES_DB: ${POSTGRES_DB}
    ports:
      - "${PGVECTOR_PORT}:5432"
    volumes:
      - pgvector_data:/var/lib/postgresql/data
    restart: unless-stopped  
#OPEA Retriever Microservice
  retriever:
    image: opea/retriever:latest
    container_name: opea_retriever
    ports:
      - "7000:7000"
    expose:
     - "7000"
    environment:
      PG_CONNECTION_STRING: "${DATABASE_URL}"
      TEI_ENDPOINT: "http://tei_service:80/v1/embeddings"
      INDEX_NAME: documents
      RETRIEVE_MODEL_ID: "BAAI/bge-base-en-v1.5"
      RETRIEVER_COMPONENT_NAME: "OPEA_RETRIEVER_PGVECTOR"
      COLLECTION_NAME: "documents"

    ipc: host
    depends_on:
      - tei_service
      - pgvector_db
volumes:
  pgvector_data: